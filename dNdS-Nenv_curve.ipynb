{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as nrand\n",
    "from scipy.stats import norm, rv_continuous, pearsonr, spearmanr\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import time\n",
    "from statsmodels.distributions.empirical_distribution import ECDF, monotone_fn_inverter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_PCC(env_mut_fit_list):\n",
    "    N = env_mut_fit_list.shape[0]\n",
    "    if N == 1:\n",
    "        return False\n",
    "    else:\n",
    "        PCC_matrix = np.corrcoef(env_mut_fit_list)\n",
    "        return PCC_matrix[np.triu_indices(N,k=1)].mean()\n",
    "\n",
    "def average_CV(env_mut_fit_list):\n",
    "    N = env_mut_fit_list.shape[0]\n",
    "    if N == 1:\n",
    "        return False\n",
    "    else:\n",
    "        std = env_mut_fit_list.std(axis=0,ddof=1)\n",
    "        mean = env_mut_fit_list.mean(axis=0)\n",
    "        return np.mean(std/mean)\n",
    "    \n",
    "def average_std(env_mut_fit_list):\n",
    "    N = env_mut_fit_list.shape[0]\n",
    "    if N == 1:\n",
    "        return False\n",
    "    else:\n",
    "        std = env_mut_fit_list[:,(env_mut_fit_list>1).sum(axis=0)>0].std(axis=0,ddof=1).mean()\n",
    "        return std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mut_fit_list: list of fitness value\n",
    "## N_env: number of enviornment\n",
    "## env_variance: fitness variance due to change of enviornments\n",
    "# The function first ordered the original fitness list, so the index of each element in list\n",
    "# correspond to their ranking in the list. Then add normal distributed noise\n",
    "# to each of fitness value in the list, then get the fitness ranking of each fitness, \n",
    "# according to this ranking, we shuffled the original ordered fitness list, and get the new\n",
    "# fitness list in a new environment while maintaining the same shape of distribution.\n",
    "# This process is repeated N_env times, then the average fitness will be calculated.\n",
    "\n",
    "def average_env_fit(mut_fit_list_rev_cdf,N_mut,N_env,env_variance,se_list):\n",
    "    env_mut_fit_list = []\n",
    "    mut_fit_list = mut_fit_list_rev_cdf(nrand.rand(N_mut)) # using continious distribution\n",
    "    mut_fit_list.sort()\n",
    "    for i in range(N_env):\n",
    "        tmp_array = mut_fit_list + nrand.normal(scale=env_variance,size=N_mut)\n",
    "        order = tmp_array.argsort()\n",
    "        ranks = order.argsort()\n",
    "        mut_fit_list_new = mut_fit_list_rev_cdf(nrand.rand(N_mut))\n",
    "        mut_fit_list_new.sort()\n",
    "        mut_fit_list_new = mut_fit_list_new[ranks]\n",
    "        #### introduce measurement error ####\n",
    "        mut_fit_list_new = nrand.normal(\n",
    "            loc = mut_fit_list_new, \n",
    "            scale= se_list\n",
    "        )\n",
    "        env_mut_fit_list.append(mut_fit_list_new)\n",
    "        \n",
    "    env_mut_fit_list = np.array(env_mut_fit_list)\n",
    "    CV = average_CV(env_mut_fit_list)    \n",
    "    lowest = env_mut_fit_list.min(axis=0) # use the minimum\n",
    "    \n",
    "    return lowest, CV, env_mut_fit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_env_given_CV will do a automatic search to fit the calculated CV to the target CV,\n",
    "# and return a list of across-environments-averaged fitness distribution with preset replication.\n",
    "\n",
    "def get_env_given_CV(mut_fit_list_rev_cdf,N_mut,N_env,target_CV,mut_type,cutoff = 0.0001, rep=1):\n",
    "    if mut_type == 'Nonsynonymous':\n",
    "        mut_idx = non_idx\n",
    "    elif mut_type == 'Synonymous':\n",
    "        mut_idx = syn_idx\n",
    "    env_variance = 0.001 # initial value of env_variance. the value will be updated during the searching\n",
    "    step_size = 0.0001 # setp_size of searching\n",
    "    direction_flag_list = [] # 1 for CV > target_CV, -1 for CV < target_CV\n",
    "    rep_list = []\n",
    "    CV_list = []\n",
    "    env_mut_fit_list_list = []\n",
    "    while True:\n",
    "        mean, CV, env_mut_fit_list = average_env_fit(\n",
    "            mut_fit_list_rev_cdf,N_mut,N_env,env_variance,\n",
    "            df_empirical[mut_idx]['YPD_fitness_se']\n",
    "        )\n",
    "        #print(env_variance,CV)\n",
    "        if CV - target_CV > cutoff:\n",
    "            # calculated CV is greater than target CV\n",
    "            direction_flag_list.append(-1)\n",
    "        \n",
    "        elif CV - target_CV < -cutoff:\n",
    "            # calculated CV is lower than target CV\n",
    "            direction_flag_list.append(1)\n",
    "        \n",
    "        else:\n",
    "            # calculated CV is within the cutoff\n",
    "            direction_flag_list.append(0)\n",
    "            rep_list.append(mean)\n",
    "            env_mut_fit_list_list.append(env_mut_fit_list)\n",
    "            CV_list.append(CV)\n",
    "            if len(rep_list) == rep:\n",
    "                break\n",
    "            continue\n",
    "        \n",
    "        if len(direction_flag_list) >= 2 and direction_flag_list[-1]*direction_flag_list[-2] == -1:\n",
    "            # update step_size according to the state of last two direction flag\n",
    "            step_size = step_size/2\n",
    "        \n",
    "        # update env_variance according to step_size and direction flag\n",
    "        env_variance += step_size*direction_flag_list[-1]\n",
    "    \n",
    "    return np.array(rep_list), CV_list, env_mut_fit_list_list\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_env(env_mut_fit_list_all,N_env,rep):\n",
    "    env_mut_fit_list_list = []\n",
    "    mean_list = []\n",
    "    CV_list = []\n",
    "    N_all = len(env_mut_fit_list_all)\n",
    "    for i in range(rep):\n",
    "        idx = nrand.choice(range(N_all),N_env,replace=False)\n",
    "        env_mut_fit_list = env_mut_fit_list_all[idx]\n",
    "        mean = np.exp(np.log(env_mut_fit_list).mean(axis=0))\n",
    "        env_mut_fit_list_list.append(env_mut_fit_list)\n",
    "        mean_list.append(mean)\n",
    "        CV_list.append(average_CV(env_mut_fit_list))\n",
    "    env_mut_fit_list_list = np.array(env_mut_fit_list_list)\n",
    "    mean_list = np.array(mean_list)\n",
    "    CV_list = np.array(CV_list)\n",
    "    return mean_list, CV_list, env_mut_fit_list_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empirical  = pd.read_csv('All_mutations_four_env_SNF6_two_replicates_se.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert empirical descrete DFE to smooth DFE.\n",
    "non_idx = df_empirical['Mutation_type'] == 'Nonsynonymous_mutation'\n",
    "syn_idx = df_empirical['Mutation_type'] == 'Synonymous_mutation'\n",
    "non_E_distribution = df_empirical[non_idx]['YPD_fitness'].to_numpy().flatten()\n",
    "syn_E_distribution = df_empirical[syn_idx]['YPD_fitness'].to_numpy().flatten()\n",
    "non_cdf = ECDF(non_E_distribution)\n",
    "syn_cdf = ECDF(syn_E_distribution)\n",
    "non_fit_list_rev_cdf = \\\n",
    "    monotone_fn_inverter(non_cdf,np.concatenate([[0],non_cdf.x[1:]]))\n",
    "syn_fit_list_rev_cdf = \\\n",
    "    monotone_fn_inverter(syn_cdf,np.concatenate([[0],syn_cdf.x[1:]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### parameters need to tune ####\n",
    "\n",
    "replication = 1000\n",
    "N_env_list = list(range(1,10))+list(range(10,40,2))+list(range(40,100,10))+list(range(100,201,50)) # number of environment\n",
    "N_non = len(non_E_distribution)\n",
    "N_syn = len(syn_E_distribution)\n",
    "target_CV_list = [[0.008,0.003],[0.008,0.004],[0.008,0.005]] # target CV\n",
    "cutoff_list = [0.98,0.99] # fitness cutoff for purging mutations\n",
    "res_dict = {\n",
    "    'N_env':[],'target_non_CV':[],'target_syn_CV':[],'rep':[],'cutoff':[],'dN':[],'dS':[],\n",
    "    'non_CV':[], 'syn_CV':[]\n",
    "}\n",
    "\n",
    "##################################\n",
    "\n",
    "for target_CV in target_CV_list:\n",
    "    print(target_CV)\n",
    "    if target_CV[1] in res_dict['target_syn_CV']:\n",
    "        continue\n",
    "        \n",
    "    for N_env in N_env_list:\n",
    "        print(N_env)\n",
    "        if N_env == 1:\n",
    "            non_mean_list = np.array([non_E_distribution]*replication)\n",
    "            syn_mean_list = np.array([syn_E_distribution]*replication)\n",
    "            non_CV_list = [np.nan]*replication\n",
    "            syn_CV_list = [np.nan]*replication\n",
    "        else:  \n",
    "            # get_env_given_CV will do a automatic search to fit the calculated CV to the target CV,\n",
    "            # and return a list of across-environments-averaged fitness distribution with preset replication.\n",
    "            non_mean_list, non_CV_list, non_env_mut_fit_list_list = get_env_given_CV(\n",
    "                non_fit_list_rev_cdf,\n",
    "                N_non, N_env, target_CV[0],'Nonsynonymous',\n",
    "                cutoff = 0.0001,\n",
    "                rep=replication\n",
    "            )\n",
    "            \n",
    "            syn_mean_list, syn_CV_list, syn_env_mut_fit_list_list = get_env_given_CV(\n",
    "                syn_fit_list_rev_cdf,\n",
    "                N_syn, N_env,target_CV[1],'Synonymous',\n",
    "                cutoff = 0.0001,\n",
    "                rep=replication\n",
    "            )\n",
    "\n",
    "        for cutoff in cutoff_list:\n",
    "            dN_list = (non_mean_list>cutoff).sum(axis=1)/N_non\n",
    "            dS_list = (syn_mean_list>cutoff).sum(axis=1)/N_syn\n",
    "            res_dict['N_env'] += [N_env]*replication\n",
    "            res_dict['target_non_CV'] += [target_CV[0]]*replication\n",
    "            res_dict['target_syn_CV'] += [target_CV[1]]*replication\n",
    "            res_dict['cutoff'] += [cutoff]*replication\n",
    "            res_dict['rep'] += list(range(replication))\n",
    "            #res_dict['Ne'] += [Ne]*replication\n",
    "            res_dict['dN'] += list(dN_list)\n",
    "            res_dict['dS'] += list(dS_list)\n",
    "            res_dict['non_CV'] += list(non_CV_list)\n",
    "            res_dict['syn_CV'] += list(syn_CV_list)\n",
    "            \n",
    "res_df = pd.DataFrame(res_dict)\n",
    "res_df['dNdS'] = res_df.dN/res_df.dS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dict = {\n",
    "    'N_env':[],'target_non_CV':[],'target_syn_CV':[],'cutoff':[],'dNdS_mean':[],'dNdS_std':[],\n",
    "    'dNdS_se':[],'non_CV_mean':[],'syn_CV_mean':[],'non_CV_std':[],'syn_CV_std':[],\n",
    "    'non_CV_se':[],'syn_CV_se':[],'dN':[],'dS':[]\n",
    "}\n",
    "for target_CV in target_CV_list:\n",
    "    for N_env in N_env_list:\n",
    "        for cutoff in cutoff_list:\n",
    "            idx = (res_df.target_syn_CV == target_CV[1]) & (res_df.cutoff == cutoff)  & (res_df.N_env == N_env)\n",
    "            dN_list = res_df[idx].dN\n",
    "            dS_list = res_df[idx].dS\n",
    "            dNdS_mean = (dN_list/dS_list).mean()\n",
    "            dNdS_std = (dN_list/dS_list).std()\n",
    "            dNdS_se = (dN_list/dS_list).sem()\n",
    "            res_df[idx].non_CV\n",
    "            res_df[idx].syn_CV\n",
    "            plot_dict['N_env'].append(N_env)\n",
    "            plot_dict['target_non_CV'].append(target_CV[0])\n",
    "            plot_dict['target_syn_CV'].append(target_CV[1])\n",
    "            plot_dict['cutoff'].append(cutoff)\n",
    "            plot_dict['non_CV_mean'].append(res_df[idx].non_CV.mean())\n",
    "            plot_dict['syn_CV_mean'].append(res_df[idx].syn_CV.mean())\n",
    "            plot_dict['non_CV_std'].append(res_df[idx].non_CV.std())\n",
    "            plot_dict['syn_CV_std'].append(res_df[idx].syn_CV.std())\n",
    "            plot_dict['non_CV_se'].append(res_df[idx].non_CV.sem())\n",
    "            plot_dict['syn_CV_se'].append(res_df[idx].syn_CV.sem())\n",
    "            plot_dict['dN'].append(dN_list.mean())\n",
    "            plot_dict['dS'].append(dS_list.mean())\n",
    "            plot_dict['dNdS_mean'].append(dNdS_mean)\n",
    "            plot_dict['dNdS_std'].append(dNdS_std)\n",
    "            plot_dict['dNdS_se'].append(dNdS_se)\n",
    "plot_df = pd.DataFrame(plot_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmap = ['r','b','g']\n",
    "\n",
    "for j,target_CV in enumerate(target_CV_list):\n",
    "    fig,ax = plt.subplots(figsize=[5.2,5])\n",
    "    params = {'mathtext.default': 'regular' }          \n",
    "    plt.rcParams.update(params)\n",
    "    ax.set_title(f'Nonsynonymous $CV$={target_CV[0]}\\n Synonymous $CV$={target_CV[1]}',size=15)\n",
    "    color=['red', 'green', 'blue']\n",
    "    for i,cutoff in enumerate(cutoff_list):\n",
    "        idx = (plot_df.target_syn_CV == target_CV[1]) & (plot_df.cutoff == cutoff)\n",
    "        x = plot_df[idx].N_env\n",
    "        y = plot_df[idx].dNdS_mean\n",
    "        ax.plot(x, y, lw=2, label = f'Fitness cutoff = {cutoff}')\n",
    "        ax.fill_between(plot_df[idx].N_env,\n",
    "                        plot_df[idx].dNdS_mean-plot_df[idx].dNdS_std*1.96,\n",
    "                        plot_df[idx].dNdS_mean+plot_df[idx].dNdS_std*1.96, alpha=.3)\n",
    "        ax.set_xlabel(\"Number of different environments\",size=15)\n",
    "        ax.set_ylabel(\"Expected $\\mathit{d}_{N}/\\mathit{d}_{S}$\",size=15)\n",
    "        ax.legend(fontsize='large')\n",
    "    ax.set_xlim(-1,200)\n",
    "    ax.set_ylim(-0.1,1.1)\n",
    "    plt.xticks(fontsize=12)\n",
    "    plt.yticks(fontsize=12)\n",
    "    #plt.savefig(f'lowest_with_se_{int(target_CV[0]*1000)}{int(target_CV[1]*1000)}.pdf')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
