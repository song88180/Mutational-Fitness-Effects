{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as nrand\n",
    "from scipy.stats import norm, rv_continuous\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "def get_natural_cubic_spline_model(x, y, minval=None, maxval=None, n_knots=None, knots=None):\n",
    "    \"\"\"\n",
    "    Get a natural cubic spline model for the data.\n",
    "\n",
    "    For the knots, give (a) `knots` (as an array) or (b) minval, maxval and n_knots.\n",
    "\n",
    "    If the knots are not directly specified, the resulting knots are equally\n",
    "    space within the *interior* of (max, min).  That is, the endpoints are\n",
    "    *not* included as knots.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: np.array of float\n",
    "        The input data\n",
    "    y: np.array of float\n",
    "        The outpur data\n",
    "    minval: float \n",
    "        Minimum of interval containing the knots.\n",
    "    maxval: float \n",
    "        Maximum of the interval containing the knots.\n",
    "    n_knots: positive integer \n",
    "        The number of knots to create.\n",
    "    knots: array or list of floats \n",
    "        The knots.\n",
    "\n",
    "    Returns\n",
    "    --------\n",
    "    model: a model object\n",
    "        The returned model will have following method:\n",
    "        - predict(x):\n",
    "            x is a numpy array. This will return the predicted y-values.\n",
    "    \"\"\"\n",
    "\n",
    "    if knots:\n",
    "        spline = NaturalCubicSpline(knots=knots)\n",
    "    else:\n",
    "        spline = NaturalCubicSpline(max=maxval, min=minval, n_knots=n_knots)\n",
    "\n",
    "    p = Pipeline([\n",
    "        ('nat_cubic', spline),\n",
    "        ('regression', LinearRegression(fit_intercept=True))\n",
    "    ])\n",
    "\n",
    "    p.fit(x, y)\n",
    "\n",
    "    return p\n",
    "\n",
    "\n",
    "class AbstractSpline(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Base class for all spline basis expansions.\"\"\"\n",
    "\n",
    "    def __init__(self, max=None, min=None, n_knots=None, n_params=None, knots=None):\n",
    "        if knots is None:\n",
    "            if not n_knots:\n",
    "                n_knots = self._compute_n_knots(n_params)\n",
    "            knots = np.linspace(min, max, num=(n_knots + 2))[1:-1]\n",
    "            max, min = np.max(knots), np.min(knots)\n",
    "        self.knots = np.asarray(knots)\n",
    "\n",
    "    @property\n",
    "    def n_knots(self):\n",
    "        return len(self.knots)\n",
    "\n",
    "    def fit(self, *args, **kwargs):\n",
    "        return self\n",
    "\n",
    "\n",
    "class NaturalCubicSpline(AbstractSpline):\n",
    "    \"\"\"Apply a natural cubic basis expansion to an array.\n",
    "    The features created with this basis expansion can be used to fit a\n",
    "    piecewise cubic function under the constraint that the fitted curve is\n",
    "    linear *outside* the range of the knots..  The fitted curve is continuously\n",
    "    differentiable to the second order at all of the knots.\n",
    "    This transformer can be created in two ways:\n",
    "      - By specifying the maximum, minimum, and number of knots.\n",
    "      - By specifying the cutpoints directly.  \n",
    "\n",
    "    If the knots are not directly specified, the resulting knots are equally\n",
    "    space within the *interior* of (max, min).  That is, the endpoints are\n",
    "    *not* included as knots.\n",
    "    Parameters\n",
    "    ----------\n",
    "    min: float \n",
    "        Minimum of interval containing the knots.\n",
    "    max: float \n",
    "        Maximum of the interval containing the knots.\n",
    "    n_knots: positive integer \n",
    "        The number of knots to create.\n",
    "    knots: array or list of floats \n",
    "        The knots.\n",
    "    \"\"\"\n",
    "\n",
    "    def _compute_n_knots(self, n_params):\n",
    "        return n_params\n",
    "\n",
    "    @property\n",
    "    def n_params(self):\n",
    "        return self.n_knots - 1\n",
    "\n",
    "    def transform(self, X, **transform_params):\n",
    "        X_spl = self._transform_array(X)\n",
    "        if isinstance(X, pd.Series):\n",
    "            col_names = self._make_names(X)\n",
    "            X_spl = pd.DataFrame(X_spl, columns=col_names, index=X.index)\n",
    "        return X_spl\n",
    "\n",
    "    def _make_names(self, X):\n",
    "        first_name = \"{}_spline_linear\".format(X.name)\n",
    "        rest_names = [\"{}_spline_{}\".format(X.name, idx)\n",
    "                      for idx in range(self.n_knots - 2)]\n",
    "        return [first_name] + rest_names\n",
    "\n",
    "    def _transform_array(self, X, **transform_params):\n",
    "        X = X.squeeze()\n",
    "        try:\n",
    "            X_spl = np.zeros((X.shape[0], self.n_knots - 1))\n",
    "        except IndexError: # For arrays with only one element\n",
    "            X_spl = np.zeros((1, self.n_knots - 1))\n",
    "        X_spl[:, 0] = X.squeeze()\n",
    "\n",
    "        def d(knot_idx, x):\n",
    "            def ppart(t): return np.maximum(0, t)\n",
    "\n",
    "            def cube(t): return t*t*t\n",
    "            numerator = (cube(ppart(x - self.knots[knot_idx]))\n",
    "                         - cube(ppart(x - self.knots[self.n_knots - 1])))\n",
    "            denominator = self.knots[self.n_knots - 1] - self.knots[knot_idx]\n",
    "            return numerator / denominator\n",
    "\n",
    "        for i in range(0, self.n_knots - 2):\n",
    "            X_spl[:, i+1] = (d(i, X) - d(self.n_knots - 2, X)).squeeze()\n",
    "        return X_spl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_PCC(env_mut_fit_list):\n",
    "    N = env_mut_fit_list.shape[0]\n",
    "    if N == 1:\n",
    "        return False\n",
    "    else:\n",
    "        PCC_matrix = np.corrcoef(env_mut_fit_list)\n",
    "        return PCC_matrix[np.triu_indices(N,k=1)].mean()\n",
    "\n",
    "def average_CV(env_mut_fit_list):\n",
    "    N = env_mut_fit_list.shape[0]\n",
    "    if N == 1:\n",
    "        return False\n",
    "    else:\n",
    "        std = env_mut_fit_list.std(axis=0,ddof=1)\n",
    "        mean = env_mut_fit_list.mean(axis=0)\n",
    "        return np.mean(std/mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mut_fit_list: list of fitness value\n",
    "## N_env: number of enviornment\n",
    "## env_variance: fitness variance due to change of enviornments\n",
    "# The function first ordered the original fitness list, so the index of each element in list\n",
    "# correspond to their ranking in the list. Then add normal distributed noise\n",
    "# to each of fitness value in the list, then get the fitness ranking of each fitness, \n",
    "# according to this ranking, we shuffled the original ordered fitness list, and get the new\n",
    "# fitness list in a new environment while maintaining the same shape of distribution.\n",
    "# This process is repeated N_env times, then the average fitness will be calculated.\n",
    "\n",
    "def average_env_fit(mut_fit_list,N_env,env_variance):\n",
    "    env_mut_fit_list = []\n",
    "    mut_fit_list.sort()\n",
    "    mut_fit_list = np.array(mut_fit_list)\n",
    "    N = len(mut_fit_list)\n",
    "    for i in range(N_env):\n",
    "        tmp_array = mut_fit_list + nrand.normal(scale=env_variance,size=N)\n",
    "        order = tmp_array.argsort()\n",
    "        ranks = order.argsort()\n",
    "        env_mut_fit_list.append(mut_fit_list[ranks])\n",
    "    env_mut_fit_list = np.array(env_mut_fit_list)\n",
    "    #PCC = average_PCC(env_mut_fit_list)\n",
    "    CV = average_CV(env_mut_fit_list)    \n",
    "    #mean = np.exp(np.log(env_mut_fit_list).mean(axis=0)) # changed to use geometric mean.\n",
    "    mean = env_mut_fit_list.min(axis=0) # use the minimum\n",
    "    return mean, CV, env_mut_fit_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_env_given_CV will do a automatic search to fit the calculated CV to the target CV,\n",
    "# and return a list of across-environments-averaged fitness distribution with preset replication.\n",
    "\n",
    "def get_env_given_CV(mut_fit_list,N_env,target_CV,cutoff = 0.0001, rep=1):\n",
    "    env_variance = 0.01 # initial value of env_variance. the value will be updated during the searching\n",
    "    step_size = 0.005 # setp_size of searching\n",
    "    direction_flag_list = [] # 1 for CV > target_CV, -1 for CV < target_CV\n",
    "    rep_list = []\n",
    "    CV_list = []\n",
    "    env_mut_fit_list_list = []\n",
    "    while True:\n",
    "        mean, CV, env_mut_fit_list = average_env_fit(mut_fit_list,N_env,env_variance)\n",
    "        \n",
    "        if CV - target_CV > cutoff:\n",
    "            # calculated CV is greater than target CV\n",
    "            direction_flag_list.append(-1)\n",
    "        \n",
    "        elif CV - target_CV < -cutoff:\n",
    "            # calculated CV is lower than target CV\n",
    "            direction_flag_list.append(1)\n",
    "        \n",
    "        else:\n",
    "            # calculated CV is within the cutoff\n",
    "            direction_flag_list.append(0)\n",
    "            rep_list.append(mean)\n",
    "            env_mut_fit_list_list.append(env_mut_fit_list)\n",
    "            CV_list.append(CV)\n",
    "            if len(rep_list) == rep:\n",
    "                break\n",
    "        \n",
    "        if len(direction_flag_list) >= 2 and direction_flag_list[-1]*direction_flag_list[-2] == -1:\n",
    "            # update step_size according to the state of last two direction flag\n",
    "            step_size = step_size/2\n",
    "        \n",
    "        # update env_variance according to step_size and direction flag\n",
    "        env_variance += step_size*direction_flag_list[-1]\n",
    "    \n",
    "    return np.array(rep_list), CV_list, env_mut_fit_list_list\n",
    "        \n",
    "def add_env_given_CV(mut_fit_list, env_mut_fit_list_list, N_env, target_CV, cutoff = 0.0001, rep=1):\n",
    "    env_variance = 0.01 # initial value of env_variance. the value will be updated during the searching\n",
    "    step_size = 0.005 # setp_size of searching\n",
    "    direction_flag_list = [] # 1 for CV > target_CV, -1 for CV < target_CV\n",
    "    rep_list = []\n",
    "    CV_list = []\n",
    "    additional_N_env = N_env - len(env_mut_fit_list_list[0])\n",
    "    new_env_mut_fit_list_list = []\n",
    "    ii = 0\n",
    "    while True:\n",
    "        _, _, env_mut_fit_list = average_env_fit(mut_fit_list,additional_N_env,env_variance)\n",
    "        \n",
    "        new_env_mut_fit_list = np.concatenate([env_mut_fit_list_list[ii],env_mut_fit_list])\n",
    "        \n",
    "        CV = average_CV(new_env_mut_fit_list)\n",
    "        \n",
    "        if CV - target_CV > cutoff:\n",
    "            # calculated CV is greater than target CV\n",
    "            direction_flag_list.append(-1)\n",
    "        \n",
    "        elif CV - target_CV < -cutoff:\n",
    "            # calculated CV is lower than target CV\n",
    "            direction_flag_list.append(1)\n",
    "        \n",
    "        else:\n",
    "            # calculated CV is within the cutoff\n",
    "            direction_flag_list.append(0)\n",
    "            rep_list.append(new_env_mut_fit_list.min(axis=0))\n",
    "            CV_list.append(CV)\n",
    "            new_env_mut_fit_list_list.append(new_env_mut_fit_list)\n",
    "            ii += 1\n",
    "            if len(rep_list) == rep:\n",
    "                break\n",
    "        \n",
    "        if len(direction_flag_list) >= 2 and direction_flag_list[-1]*direction_flag_list[-2] == -1:\n",
    "            # update step_size according to the state of last two direction flag\n",
    "            step_size = step_size/2\n",
    "        \n",
    "        # update env_variance according to step_size and direction flag\n",
    "        env_variance += step_size*direction_flag_list[-1]\n",
    "        if env_variance < 0: env_variance = 0\n",
    "    \n",
    "    return np.array(rep_list), CV_list, new_env_mut_fit_list_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empirical  = pd.read_csv('All_mutations_four_env_SNF6_two_replicates-fitness.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empirical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_fit_list = non_fit_list = df_empirical['YPD-fitness'].to_numpy().flatten()\n",
    "syn_fit_list.sort()\n",
    "non_fit_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### parameters need to tune ####\n",
    "\n",
    "replication = 10 #10\n",
    "N_env_list = list(range(1,10))+list(range(10,40,2))+list(range(40,100,10))+list(range(100,201,100)) # number of environment\n",
    "target_CV_list = [[0.008,0.006],[0.008,0.005],[0.008,0.004],[0.008,0.003]] # target CV\n",
    "cutoff_list = [0.98,0.99,0.995] # fitness cutoff for purging mutations\n",
    "res_dict = {'N_env':[],'target_non_CV':[],'target_syn_CV':[],'rep':[],'cutoff':[],'dN':[],'dS':[]}\n",
    "\n",
    "##################################\n",
    "\n",
    "for target_CV in target_CV_list:\n",
    "    print(target_CV)\n",
    "    if target_CV[1] in res_dict['target_syn_CV']:\n",
    "        continue\n",
    "    for N_env in N_env_list:\n",
    "        #print(N_env)\n",
    "        if N_env == 1:\n",
    "            non_mean_list = np.array([non_fit_list]*replication)\n",
    "            syn_mean_list = np.array([syn_fit_list]*replication)\n",
    "        else:\n",
    "            # get_env_given_CV will do a automatic search to fit the calculated CV to the target CV,\n",
    "            # and return a list of across-environments-averaged fitness distribution with preset replication.\n",
    "            non_mean_list, CV_list, non_env_mut_fit_list_list = get_env_given_CV(\n",
    "                non_fit_list,\n",
    "                N_env,target_CV[0],\n",
    "                cutoff = 0.0001,\n",
    "                rep=replication\n",
    "            )\n",
    "            syn_mean_list, CV_list, syn_env_mut_fit_list_list = get_env_given_CV(\n",
    "                syn_fit_list,\n",
    "                N_env,target_CV[1],\n",
    "                cutoff = 0.0001,\n",
    "                rep=replication\n",
    "            )\n",
    "\n",
    "        for cutoff in cutoff_list:\n",
    "            dN_list = np.sum(non_mean_list>cutoff,axis=1)/len(non_fit_list)\n",
    "            dS_list = np.sum(syn_mean_list>cutoff,axis=1)/len(syn_fit_list)\n",
    "            res_dict['N_env'] += [N_env]*replication\n",
    "            res_dict['target_non_CV'] += [target_CV[0]]*replication\n",
    "            res_dict['target_syn_CV'] += [target_CV[1]]*replication\n",
    "            res_dict['rep'] += list(range(replication))\n",
    "            res_dict['cutoff'] += [cutoff]*replication\n",
    "            res_dict['dN'] += list(dN_list)\n",
    "            res_dict['dS'] += list(dS_list)\n",
    "            \n",
    "\n",
    "res_df = pd.DataFrame(res_dict)\n",
    "res_df['dNdS'] = res_df.dN/res_df.dS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dict = {'N_env':[],'target_non_CV':[],'target_syn_CV':[],'cutoff':[],'dNdS_mean':[],'dNdS_std':[]}\n",
    "for target_CV in target_CV_list:\n",
    "    for N_env in N_env_list:\n",
    "        for cutoff in cutoff_list:\n",
    "            idx = (res_df.target_syn_CV == target_CV[1]) & (res_df.cutoff == cutoff)  & (res_df.N_env == N_env)\n",
    "            dN_list = res_df[idx].dN\n",
    "            dS_list = res_df[idx].dS\n",
    "            dNdS_mean = (dN_list/dS_list).mean()\n",
    "            dNdS_std = (dN_list/dS_list).std()\n",
    "            plot_dict['N_env'].append(N_env)\n",
    "            plot_dict['target_non_CV'].append(target_CV[0])\n",
    "            plot_dict['target_syn_CV'].append(target_CV[1])\n",
    "            plot_dict['cutoff'].append(cutoff)\n",
    "            plot_dict['dNdS_mean'].append(dNdS_mean)\n",
    "            plot_dict['dNdS_std'].append(dNdS_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = pd.DataFrame(plot_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_CV_list_plot=[[0.008, 0.003],\n",
    "                     [0.008, 0.004],\n",
    "                     [0.008, 0.005],\n",
    "                     [0.008, 0.006]]\n",
    "cutoff_list_plot = [0.98,0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmap = ['r','b','g']\n",
    "fig,axes = plt.subplots(1,4,figsize=[22,5])\n",
    "for j,target_CV in enumerate(target_CV_list_plot):\n",
    "    ax = axes[j]\n",
    "    ax.set_title(f'Nonsynonymous $CV$={target_CV[0]}\\n Synonymous $CV$={target_CV[1]}',size=15)\n",
    "    color=['red', 'green', 'blue']\n",
    "    for i,cutoff in enumerate(cutoff_list_plot):\n",
    "        idx = (plot_df.target_syn_CV == target_CV[1]) & (plot_df.cutoff == cutoff)\n",
    "        x = plot_df[idx].N_env\n",
    "        y = plot_df[idx].dNdS_mean\n",
    "        x_plot = np.linspace(1,101,100)\n",
    "        model_6 = get_natural_cubic_spline_model(x, y, minval=min(x), maxval=max(x), n_knots=20, \n",
    "                                                 knots = [1,4,7,10,20,30,40,100])\n",
    "        y_plot = model_6.predict(x_plot)\n",
    "        ax.plot(x, y, lw=2, label = f'Fitness cutoff={cutoff}')\n",
    "        ax.set_ylim(-0.1,1.1)\n",
    "        ax.set_xlim(-5,200)\n",
    "        ax.fill_between(plot_df[idx].N_env,\n",
    "                        plot_df[idx].dNdS_mean-plot_df[idx].dNdS_std*1.96,\n",
    "                        plot_df[idx].dNdS_mean+plot_df[idx].dNdS_std*1.96, alpha=.3)\n",
    "        ax.set_xlabel(\"Number of different environments\",size=15)\n",
    "        ax.set_ylabel(\"Expected dN/dS\",size=15)\n",
    "        ax.legend()\n",
    "#plt.savefig('simulation.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
